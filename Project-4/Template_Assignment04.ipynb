{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Iqxc0E5rFc_"
      },
      "source": [
        "# This is the python template for Assignment 04.  \n",
        "- You must use this template.  \n",
        "- You must not change any signatures of the methods, only edit the sections indicated with \"Write your code here.\"  \n",
        "- The return of every function has to be in the right format, otherwise this is a desk reject.  \n",
        "- Plagiarism leads to failing the assignment!  \n",
        "- We will terminate the script after 10 min, try to use efficient algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VFHU4BCNrFdC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C72-HOUjrFdF"
      },
      "outputs": [],
      "source": [
        "def get_name():\n",
        "    return \"Irem Begüm Gündüz\"\n",
        "def get_matriculationnumber():\n",
        "    return 7026821"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IizOf4UzrFdI"
      },
      "source": [
        "## Useful information:\n",
        "\n",
        "The structure of a CART is a dict. Use the same names as shown in the example, using other names makes your format invalid and leads to a desk reject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_e1560zrFdJ"
      },
      "outputs": [],
      "source": [
        "cart = { \"name\":\"X\", \"mean\":456, \"split_by_feature\": \"aes\", \"error_of_split\": 0.0,\n",
        "        \"successor_left\": { \"name\":\"XL\", \"mean\":1234, \"split_by_feature\": None, \"error_of_split\":None,\n",
        "                           \"successor_left\":None,\n",
        "                           \"successor_right\":None\n",
        "                          },\n",
        "        \"successor_right\":{ \"name\":\"XR\", \"mean\":258, \"split_by_feature\": None,\"error_of_split\":None,\n",
        "                           \"successor_left\":None,\n",
        "                           \"successor_right\":None\n",
        "                          }\n",
        "       }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwvVaIz9rFdL"
      },
      "source": [
        "The names of the features must be used as defined in this list, using other names makes your format invalid and leads to a desk reject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68cwhzvCrFdL"
      },
      "outputs": [],
      "source": [
        "features = [\"secompress\", \"encryption\", \"aes\", \"blowfish\", \"algorithm\", \"rar\", \"zip\", \"signature\",\n",
        "            \"timestamp\", \"segmentation\", \"onehundredmb\", \"onegb\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BF_1CHLrFdL"
      },
      "source": [
        "# Task 1: Create a CART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wICjZ9XmrFdM"
      },
      "outputs": [],
      "source": [
        "def compute_performance(dataframe,dataframe2=pd.DataFrame(),metric= \"performance\"):\n",
        "  #compute the performance of given dataframe(S)\n",
        "    if  dataframe2.empty:\n",
        "         feature = extract_features(dataframe)\n",
        "         results_table = compute_performance_helper(dataframe,feature, metric)\n",
        "         return results_table\n",
        "    else:\n",
        "       features,features2 = extract_features(dataframe,dataframe2)\n",
        "       results_table = compute_performance_helper(dataframe,features, metric)\n",
        "       results_table2 = compute_performance_helper(dataframe2,features2, metric)\n",
        "       return results_table, results_table2\n",
        "\n",
        "def compute_performance_helper(dataframe,features, metric= \"performance\"):\n",
        "    # Initialize a results dataframe\n",
        "    results_table = results_helper_df()\n",
        "    \n",
        "    for feature in features:\n",
        "        # Split the dataframe into two based on the feature\n",
        "        left_data = dataframe[dataframe[feature] == 1]\n",
        "        right_data = dataframe[dataframe[feature] == 0]\n",
        "\n",
        "        # Count the number of observations in each split\n",
        "        left_count = len(left_data)\n",
        "        right_count = len(right_data)\n",
        "\n",
        "        # Sum the values of the metric in each split\n",
        "        left_sum = left_data[metric].sum()\n",
        "        right_sum = right_data[metric].sum()\n",
        "\n",
        "        # Calculate the mean of the metric in each split\n",
        "        if left_count != 0: \n",
        "          left_mean = round(left_sum / left_count,2) \n",
        "        else: \n",
        "          left_mean = 0\n",
        "\n",
        "        if right_count != 0: \n",
        "          right_mean = round(right_sum / right_count,2)\n",
        "        else: \n",
        "          right_mean = 0\n",
        "\n",
        "        # Calculate the squared error of the metric in each split\n",
        "        left_sq_err = ((left_data[metric] - left_mean) ** 2).sum()\n",
        "        right_sq_err = ((right_data[metric] - right_mean) ** 2).sum()\n",
        "        left_sq_err, right_sq_err = round(left_sq_err, 2), round(right_sq_err, 2)\n",
        "\n",
        "        # Calculate the total squared error and mean of the metric\n",
        "        total_sq_err = left_sq_err + right_sq_err\n",
        "        total_mean = round((left_sum + right_sum) / (left_count + right_count), 2)\n",
        "\n",
        "        # Create a result list and append it to the results DataFrame\n",
        "        result = [feature, left_count, left_mean, left_sq_err, right_count, right_mean, right_sq_err, total_mean, total_sq_err]\n",
        "        results_table.loc[len(results_table)] = result\n",
        "    return results_table \n",
        "\n",
        "def results_helper_df():\n",
        "    #create an empty dataframe\n",
        "    results_df = pd.DataFrame(columns=['feature', 'left_count', 'left_mean', \n",
        "                                       'left_sq_err', 'right_count', 'right_mean',\n",
        "                                       'right_sq_err', 'total_mean', 'total_sq_err'])\n",
        "    return results_df\n",
        "\n",
        "def extract_features(df,df2=pd.DataFrame()):\n",
        "    #extract features from columns by disgarding id and performance\n",
        "    features = [col for col in df.columns if col != 'performance' and col != 'Id']\n",
        "    if  df2.size == 0: \n",
        "      return features\n",
        "    else :\n",
        "      features2 = [col for col in df2.columns if col != 'performance' and col != 'Id']\n",
        "      return features,features2\n",
        "\n",
        "def get_split_var(df, tot_error_col='total_sq_err', feature_col='feature'):\n",
        "  # check if any value in the tot_error_col is None\n",
        "  if df[tot_error_col].isna().any() or df[tot_error_col].min() == None:\n",
        "    return None\n",
        "  # check if minimum value in the tot_error_col is None\n",
        "  min_error = df[tot_error_col].min()\n",
        "\n",
        "  # Count the number of times the minimum value appears in the column\n",
        "  counts_min = df[tot_error_col].value_counts()[min_error]\n",
        "\n",
        "  # if there is only one feature with the minimum error extract the split var\n",
        "  if counts_min == 1:\n",
        "    split_var = df.loc[df[tot_error_col] == min_error, feature_col].values[0]\n",
        "  else:\n",
        "    df_min = df.query(f'{tot_error_col} == @min_error')\n",
        "    #if all features have the same min error return none\n",
        "    if df_min[feature_col].nunique() == df[feature_col].nunique():\n",
        "       return None\n",
        "     #else sort the features alphabetically, return the first one\n",
        "    split_var = df_min[feature_col].sort_values().values[0]\n",
        "  return split_var\n",
        "\n",
        "\n",
        "def build_tree(df, results=pd.DataFrame(), feature_col='feature', totError='total_sq_err', name='X'):\n",
        "  if results.empty:\n",
        "    #compute the initial performance \n",
        "    results = compute_performance(df, metric = 'performance')\n",
        "    \n",
        "  #start an empty tree and name the first value splitting as X\n",
        "  tree = {}\n",
        "  tree['name'] = name\n",
        "  tree['mean'] = df['performance'].mean()\n",
        "  splitting_var = get_split_var(results)\n",
        "    \n",
        "  # If no more splits are possible\n",
        "  if splitting_var is None:\n",
        "    tree['split_by_feature'] = None\n",
        "    tree['error_of_split'] = None\n",
        "    tree['successor_left'] = None\n",
        "    tree['successor_right'] = None\n",
        "\n",
        "  else:\n",
        "    tree['split_by_feature'] = splitting_var\n",
        "    tree['error_of_split'] = results[results[feature_col] == splitting_var][totError].values[0]\n",
        "    left_df = df.query(f'{splitting_var} == 1')\n",
        "    left_df = left_df.drop(splitting_var, axis = 1)\n",
        "    right_df = df.query(f'{splitting_var} == 0')\n",
        "    right_df = right_df.drop(splitting_var, axis = 1)\n",
        "    \n",
        "    # Compute the performance of the left and right splits\n",
        "    results_left,results_right = compute_performance(left_df,right_df)\n",
        "    \n",
        "    # Recursively call the function to build the tree\n",
        "    tree['successor_left'] = build_tree(left_df, results_left, name=name+'L')\n",
        "    tree['successor_right'] = build_tree(right_df, results_right, name=name+'R')\n",
        "        \n",
        "  return tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZZwmNJ4CrFdM"
      },
      "outputs": [],
      "source": [
        "def get_cart(sample_set_csv):\n",
        "    # The sample_set_csv is a file path to a csv data, this can be imported into a dataframe\n",
        "    df = pd.read_csv(sample_set_csv)\n",
        "    \n",
        "    #build the cart tree\n",
        "    cart = build_tree(df)\n",
        "\n",
        "    return cart\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6hWqPbjrFdM"
      },
      "source": [
        "# Task 2a: Highest influencing feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh8RwUu8rFdM"
      },
      "outputs": [],
      "source": [
        "# Write your helper functions here, if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlVO8BqhrFdN"
      },
      "outputs": [],
      "source": [
        "def get_highest_influence_feature(cart):\n",
        "    # TODO: Write your code here. And change the return.\n",
        "    return \"secompress\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHTfhmDOrFdN"
      },
      "source": [
        "# Task 2b: Calculate the error rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSMA6IazrFdN"
      },
      "outputs": [],
      "source": [
        "# Write your helper functions here, if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxvJBDkorFdN"
      },
      "outputs": [],
      "source": [
        "def get_error_rate(cart, sample_set_csv):\n",
        "    # The sample_set_csv is a file path to a csv data, this can be imported into a dataframe\n",
        "    df = pd.read_csv(sample_set_csv)\n",
        "    # TODO: Write your code here. And change the return.\n",
        "    return 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T76MNzFWrFdO"
      },
      "source": [
        "# Task 2c: Generate optimal configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjx7t_iwrFdO"
      },
      "outputs": [],
      "source": [
        "# Write your helper functions here, if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2hnUZmGrFdO"
      },
      "outputs": [],
      "source": [
        "def get_optimal_configuration(cart, partial_configuration):\n",
        "    # TODO: Write your code here. And change the return.\n",
        "    return {\"rar\", \"timestamp\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR2IOpt0rFdO"
      },
      "source": [
        "# Tests:  \n",
        "In the following cells, we provide you some test cases (but not all possible test cases!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clzGFCoNrFdO",
        "outputId": "17c587e0-3028-40af-9c03-8b6a5f04a0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passed\n"
          ]
        }
      ],
      "source": [
        "# Task 1\n",
        "\n",
        "test_cart = {'name': 'X', 'mean': 763.2, 'split_by_feature': 'segmentation', 'error_of_split': 6.0, \n",
        "             'successor_left': \n",
        "                 {'name': 'XL', 'mean': 772.0, 'split_by_feature': 'onegb', 'error_of_split': 0.0, \n",
        "                  'successor_left': \n",
        "                      {'name': 'XLL', 'mean': 770.0, 'split_by_feature': None, 'error_of_split': None, \n",
        "                       'successor_left': None, \n",
        "                       'successor_right': None\n",
        "                      }, \n",
        "                  'successor_right': \n",
        "                      {'name': 'XLR', 'mean': 773.0, 'split_by_feature': None, 'error_of_split': None, \n",
        "                       'successor_left': None, \n",
        "                       'successor_right': None\n",
        "                      }\n",
        "                 }, \n",
        "             'successor_right': \n",
        "                 {'name': 'XR', 'mean': 750.0, 'split_by_feature': None, 'error_of_split': None, \n",
        "                  'successor_left': None, \n",
        "                  'successor_right': None}\n",
        "            }\n",
        "\n",
        "\n",
        "if get_cart(\"Performance_01.csv\") == test_cart:\n",
        "    print(\"passed\")\n",
        "else:\n",
        "    print(\"failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDWsC17CrFdP"
      },
      "outputs": [],
      "source": [
        "# Task 2b\n",
        "if get_error_rate(test_cart, \"Performance_02b.csv\") == 5:\n",
        "    print(\"passed\")\n",
        "else:\n",
        "    print(\"failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRJ0Fp6xrFdP"
      },
      "outputs": [],
      "source": [
        "# Task 2c\n",
        "test_cart_v2 = {'name': 'X', 'mean': 763.2, 'split_by_feature': 'zip', 'error_of_split': 0.0, \n",
        "                 'successor_left': {'name': 'XL', 'mean': 772.0, 'split_by_feature': None, 'error_of_split': None, \n",
        "                                    'successor_left': None, \n",
        "                                    'successor_right': None}, \n",
        "                 'successor_right': {'name': 'XR', 'mean': 750.0, 'split_by_feature': None, 'error_of_split': None, \n",
        "                                     'successor_left': None, \n",
        "                                     'successor_right': None}\n",
        "                }\n",
        "\n",
        "optimal_config = get_optimal_configuration(test_cart_v2, {\"secompress\", \"encryption\", \"aes\", \"algorithm\", \"signature\",\n",
        "                                                        \"timestamp\", \"segmentation\", \"onehundredmb\"})\n",
        "reference = {'aes', 'algorithm', 'encryption', 'onehundredmb', 'rar', 'secompress', 'segmentation', 'signature',\n",
        "            'timestamp'}\n",
        "\n",
        "if optimal_config == reference:\n",
        "    print(\"passed\")\n",
        "else:\n",
        "    print(\"failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfTseLsmrFdP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}